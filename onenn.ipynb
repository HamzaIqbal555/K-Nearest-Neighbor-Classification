{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931611cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n",
      "Total of 11314 posts in the dataset and the total size is 22.05MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train')\n",
    "data_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "pprint(data_train.target_names)\n",
    "\n",
    "print(f'Total of {len(data_train.data)} posts in the dataset and the total size is {size_mb(data_train.data):.2f}MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98ce623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few documents in the dataset:\n",
      "Document 1:\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Document 2:\n",
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n",
      "==================================================\n",
      "Document 3:\n",
      "From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\n",
      "Subject: PB questions...\n",
      "Organization: Purdue University Engineering Computer Network\n",
      "Distribution: usa\n",
      "Lines: 36\n",
      "\n",
      "well folks, my mac plus finally gave up the ghost this weekend after\n",
      "starting life as a 512k way back in 1985.  sooo, i'm in the market for a\n",
      "new machine a bit sooner than i intended to be...\n",
      "\n",
      "i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\n",
      "of questions that (hopefully) somebody can answer:\n",
      "\n",
      "* does anybody know any dirt on when the next round of powerbook\n",
      "introductions are expected?  i'd heard the 185c was supposed to make an\n",
      "appearence \"this summer\" but haven't heard anymore on it - and since i\n",
      "don't have access to macleak, i was wondering if anybody out there had\n",
      "more info...\n",
      "\n",
      "* has anybody heard rumors about price drops to the powerbook line like the\n",
      "ones the duo's just went through recently?\n",
      "\n",
      "* what's the impression of the display on the 180?  i could probably swing\n",
      "a 180 if i got the 80Mb disk rather than the 120, but i don't really have\n",
      "a feel for how much \"better\" the display is (yea, it looks great in the\n",
      "store, but is that all \"wow\" or is it really that good?).  could i solicit\n",
      "some opinions of people who use the 160 and 180 day-to-day on if its worth\n",
      "taking the disk size and money hit to get the active display?  (i realize\n",
      "this is a real subjective question, but i've only played around with the\n",
      "machines in a computer store breifly and figured the opinions of somebody\n",
      "who actually uses the machine daily might prove helpful).\n",
      "\n",
      "* how well does hellcats perform?  ;)\n",
      "\n",
      "thanks a bunch in advance for any info - if you could email, i'll post a\n",
      "summary (news reading time is at a premium with finals just around the\n",
      "corner... :( )\n",
      "--\n",
      "Tom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering\n",
      "---------------------------------------------------------------------------\n",
      "\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\n",
      "Nietzsche\n",
      "\n",
      "==================================================\n",
      "Document 4:\n",
      "From: jgreen@amber (Joe Green)\n",
      "Subject: Re: Weitek P9000 ?\n",
      "Organization: Harris Computer Systems Division\n",
      "Lines: 14\n",
      "Distribution: world\n",
      "NNTP-Posting-Host: amber.ssd.csd.harris.com\n",
      "X-Newsreader: TIN [version 1.1 PL9]\n",
      "\n",
      "Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\n",
      "> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\n",
      "> > Anyone know about the Weitek P9000 graphics chip?\n",
      "> As far as the low-level stuff goes, it looks pretty nice.  It's got this\n",
      "> quadrilateral fill command that requires just the four points.\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n",
      "--\n",
      "Joe Green\t\t\t\tHarris Corporation\n",
      "jgreen@csd.harris.com\t\t\tComputer Systems Division\n",
      "\"The only thing that really scares me is a person with no sense of humor.\"\n",
      "\t\t\t\t\t\t-- Jonathan Winters\n",
      "\n",
      "==================================================\n",
      "Document 5:\n",
      "From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\n",
      "Subject: Re: Shuttle Launch Question\n",
      "Organization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\n",
      "Distribution: sci\n",
      "Lines: 23\n",
      "\n",
      "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
      ">>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\n",
      ">>>\"Clear caution & warning memory.  Verify no unexpected\n",
      ">>>errors. ...\".  I am wondering what an \"expected error\" might\n",
      ">>>be.  Sorry if this is a really dumb question, but\n",
      "> \n",
      "> Parity errors in memory or previously known conditions that were waivered.\n",
      ">    \"Yes that is an error, but we already knew about it\"\n",
      "> I'd be curious as to what the real meaning of the quote is.\n",
      "> \n",
      "> tom\n",
      "\n",
      "\n",
      "My understanding is that the 'expected errors' are basically\n",
      "known bugs in the warning system software - things are checked\n",
      "that don't have the right values in yet because they aren't\n",
      "set till after launch, and suchlike. Rather than fix the code\n",
      "and possibly introduce new bugs, they just tell the crew\n",
      "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
      "\n",
      " - Jonathan\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"First few documents in the dataset:\")\n",
    "for i in range(5):  # Print the first 5 documents\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(data_train.data[i])  # Print the content of the document\n",
    "    print(\"=\" * 50)  # Print a separator line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303e6c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 129796\n",
      "(11314, 129796)\n",
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize Training data\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "print(f'Size of the vocabulary is {len(vectorizer.get_feature_names_out())}')\n",
    "\n",
    "# Vectorize Testing data\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e564dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DummyClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Part b: Baseline classifier using Sklearn's DummyClassifier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m baseline_clf \u001b[38;5;241m=\u001b[39m \u001b[43mDummyClassifier\u001b[49m(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m baseline_clf \u001b[38;5;241m=\u001b[39m baseline_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DummyClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Part b: Baseline classifier using Sklearn's DummyClassifier\n",
    "baseline_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline_clf = baseline_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce18d54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part c: Measure computation time for baseline classifier\n",
    "baseline_time = timeit.timeit(lambda: baseline_clf.predict(X_test), number=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "029784f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy 0.05\n",
      "Time for sample classification: 0.00014507600280921906 secs\n"
     ]
    }
   ],
   "source": [
    "# Part d: Computation time and classification accuracy \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = baseline_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Classification accuracy {acc:.2f}')\n",
    "print(\"Time for sample classification:\", baseline_time,\"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1aa1045",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n\u001b[0;32m---> 14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnearest_neighbor_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print the predictions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions)\n",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m, in \u001b[0;36mnearest_neighbor_classifier\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_sample \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[1;32m      6\u001b[0m     test_sample_dense \u001b[38;5;241m=\u001b[39m test_sample\u001b[38;5;241m.\u001b[39mtoarray()  \u001b[38;5;66;03m# Convert test sample to dense array\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_sample_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate Euclidean distances\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     nearest_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(distances)  \u001b[38;5;66;03m# Find index of the nearest neighbor\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m y_train[nearest_index]  \u001b[38;5;66;03m# Get the corresponding class label\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2557\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     s \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mconj() \u001b[38;5;241m*\u001b[39m x)\u001b[38;5;241m.\u001b[39mreal\n\u001b[0;32m-> 2557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(\u001b[43madd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mord\u001b[39m, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Part e: Implement own nearest neighbor classifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def nearest_neighbor_classifier(X_train, y_train, X_test):\n",
    "    predictions = []\n",
    "    for test_sample in X_test:\n",
    "        test_sample_dense = test_sample.toarray()  \n",
    "        distances = np.linalg.norm(X_train - test_sample_dense, axis=1) \n",
    "        nearest_index = np.argmin(distances) \n",
    "        prediction = y_train[nearest_index]  \n",
    "        predictions.append(prediction)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "predictions = nearest_neighbor_classifier(X_train, y_train, X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39d52ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 129796)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ca1fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  4  0 19  0]\n"
     ]
    }
   ],
   "source": [
    "# Part f: Computation time and classification accuracy and portion sample size\n",
    "\n",
    "# Select only 5 test samples\n",
    "X_test_subset = X_test[:5]\n",
    "y_test_subset = y_test[:5]\n",
    "predictions = nearest_neighbor_classifier(X_train, y_train, X_test_subset)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9f302a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_time = timeit.timeit(lambda: nearest_neighbor_classifier(X_train, y_train, X_test_subset), number=1)\n",
    "acc = accuracy_score(y_test_subset, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b619995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 5\n",
      "Classification accuracy 0.20\n",
      "Time for sample classification: 252.55178767200414 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Size: 5\")\n",
    "print(f'Classification accuracy {acc:.2f}')\n",
    "print(\"Time for sample classification:\", computation_time,\"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7971b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [19  4  0  3  0]\n",
      "Classification accuracy 0.20\n",
      "Time for sample classification: 0.03415647000656463 secs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = knn_classifier.predict(X_test_subset)\n",
    "computation_time = timeit.timeit(lambda: knn_classifier.predict(X_test_subset), number=1)\n",
    "acc = accuracy_score(y_test_subset, predictions)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(f'Classification accuracy {acc:.2f}')\n",
    "print(\"Time for sample classification:\", computation_time,\"secs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
